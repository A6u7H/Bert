optimizer:
  _target_: torch.optim.AdamW
  lr: 5e-4
  weight_decay: 1e-3
  betas: 
    - 0.9
    - 0.999

scheduler:
  _target_: torch.optim.lr_scheduler.StepLR 
  step_size: 30
  gamma: 0.1

loss:
  _target_: torch.nn.CrossEntropyLoss
  ignore_index: 0